{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ea7b88",
   "metadata": {},
   "source": [
    "# Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c506c2e",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c088f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
     ]
    }
   ],
   "source": [
    "import sys, os, distutils.core\n",
    "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eafa20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.structures import BoxMode, PolygonMasks\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e7075",
   "metadata": {},
   "source": [
    "## Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f33e7d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dicts(path, classes):\n",
    "    dataset_dicts = []\n",
    "    files = [file for file in os.listdir(path) if file.endswith(\".json\")]\n",
    "\n",
    "    for idx, json_filename in enumerate(files):\n",
    "        json_file = os.path.join(path, json_filename)\n",
    "        with open(json_file) as fptr:\n",
    "            img_annotations = json.load(fptr)\n",
    "\n",
    "        record = {}\n",
    "        image_filename = os.path.join(path, img_annotations[\"imagePath\"])\n",
    "        record[\"file_name\"] = image_filename\n",
    "        record[\"image_id\"] = idx\n",
    "        \n",
    "        height, width = cv2.imread(image_filename).shape[:2]\n",
    "        record[\"width\"], record[\"height\"] = width, height #720, 480\n",
    "\n",
    "        annotations = img_annotations[\"shapes\"]\n",
    "        objs = []\n",
    "        for ann in annotations:\n",
    "            px = [a[0] for a in ann[\"points\"]] # x-coordinate (top-left and bottom-right corners)\n",
    "            py = [a[1] for a in ann[\"points\"]] # y-coordinate (top-left and bottom-right corners)\n",
    "            \n",
    "            px = [px[0],px[1],px[0],px[1]]\n",
    "            py = [py[0],py[0],py[1],py[1]]\n",
    "            \n",
    "            poly = [(x, y) for x, y in zip(px, py)]\n",
    "            poly = [p for x in poly for p in x]\n",
    "\n",
    "            obj = {\"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
    "                    \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                    \"segmentation\": [poly],\n",
    "                    \"category_id\": classes.index(ann['label']),\n",
    "                    \"iscrowd\": 0}\n",
    "\n",
    "            objs.append(obj)\n",
    "\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb104f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_model(max_iter=500, save=None):\n",
    "    cfg = get_cfg()\n",
    "    cfg.MODEL.DEVICE='cpu'\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.DATASETS.TRAIN = (\"category_train\",)\n",
    "    cfg.DATASETS.TEST = ()\n",
    "    cfg.DATALOADER.NUM_WORKERS = 2\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "    cfg.SOLVER.BASE_LR = 0.00025\n",
    "    cfg.SOLVER.MAX_ITER = max_iter\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
    "    \n",
    "    if(save):\n",
    "        with open(save, 'wb') as fptr:\n",
    "            pickle.dump(cfg, fptr, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e61b4824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(cfg):\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    trainer = DefaultTrainer(cfg) \n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16dce2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_segmentation(image, labels, masks):\n",
    "    blank = np.zeros(image.shape)\n",
    "    blank[:,:] = (139, 10, 80)\n",
    "    color = None\n",
    "    for label, mask in zip(labels, masks):\n",
    "        if(not label):\n",
    "            color = (255,0,0)\n",
    "        else:\n",
    "            color = (0,0,255)\n",
    "                \n",
    "        for row in range(len(mask)):\n",
    "            for col in range(len(mask[row])):\n",
    "                if(mask[row][col]):\n",
    "                    blank[row][col] = color\n",
    "    return blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f6a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizer(image, outputs, metadata, filename=None, bounding_box=False):\n",
    "    mask = outputs[\"instances\"].get(\"pred_masks\")\n",
    "    label = outputs[\"instances\"].get(\"pred_classes\")\n",
    "    sem_seg_image = semantic_segmentation(image, label, mask)\n",
    "    plt.figure(figsize = (14, 10))\n",
    "    \n",
    "    if(bounding_box):\n",
    "        vis = Visualizer(image[:, :, ::-1], metadata=metadata, scale=0.8, instance_mode=ColorMode.SEGMENTATION)\n",
    "        vis = vis.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        plt.imshow(cv2.cvtColor(vis.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        plt.imshow(sem_seg_image)\n",
    "    \n",
    "    if(filename):\n",
    "        cv2.imwrite(os.path.join(\"./Results/\", filename), sem_seg_image)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7f080cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inferences(cfg_path, path, metadata, thresh=0.2, bounding_box=True):\n",
    "    with open(cfg_path, 'rb') as fptr:\n",
    "        cfg = pickle.load(fptr)\n",
    "    \n",
    "    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = thresh \n",
    "    cfg.DATASETS.TEST = ()\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "\n",
    "    test_dataset_dicts = get_data_dicts(path+'test', classes)\n",
    "\n",
    "    for data in random.sample(test_dataset_dicts, len(test_dataset_dicts) - 1):    \n",
    "        image = cv2.imread(data[\"file_name\"])\n",
    "        outputs = predictor(image)\n",
    "        visualizer(image, outputs, metadata, bounding_box=bounding_box)\n",
    "        \n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5280fbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(cfg_path, predictor):\n",
    "    with open(cfg_path, 'rb') as fptr:\n",
    "        cfg = pickle.load(fptr)\n",
    "        \n",
    "    evaluator = COCOEvaluator(\"category_test\", output_dir=\"./output\")\n",
    "    val_loader = build_detection_test_loader(cfg, \"category_test\")\n",
    "    print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "325156fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(cfg_path, image_path, metadata, filename=None, bounding_box=False, thresh=0.3):\n",
    "    with open(cfg_path, 'rb') as fptr:\n",
    "        cfg = pickle.load(fptr)\n",
    "    \n",
    "    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = thresh \n",
    "    \n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    image = cv2.imread(image_path)\n",
    "    outputs = predictor(image)\n",
    "    visualizer(image, outputs, metadata, filename=filename, bounding_box=bounding_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f3a784",
   "metadata": {},
   "source": [
    "## Creating Custom Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99126279",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Pebbles\", \"Large Rock\"]\n",
    "path = r\"./Images/\"\n",
    "cfg_path = r\"cfg_model.pickle\"\n",
    "\n",
    "for d in [\"train\", \"test\"]:\n",
    "    DatasetCatalog.register(\"category_\" + d, lambda d=d: get_data_dicts(path + d, classes))\n",
    "    MetadataCatalog.get(\"category_\" + d).set(thing_classes=classes)\n",
    "\n",
    "microcontroller_metadata = MetadataCatalog.get(\"category_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa28c5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6092ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/27 23:30:19 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/27 23:30:21 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 30 images left.\n",
      "\u001b[32m[10/27 23:30:21 d2.data.build]: \u001b[0mDistribution of instances among all 2 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|\n",
      "|  Pebbles   | 429          | Large Rock | 209          |\n",
      "|            |              |            |              |\n",
      "|   total    | 638          |            |              |\u001b[0m\n",
      "\u001b[32m[10/27 23:30:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[10/27 23:30:21 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/27 23:30:21 d2.data.common]: \u001b[0mSerializing 30 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/27 23:30:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.12 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/27 23:30:21 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (3, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (8, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (2, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/27 23:30:25 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/27 23:38:53 d2.utils.events]: \u001b[0m eta: 3:20:00  iter: 19  total_loss: 4.141  loss_cls: 1.069  loss_box_reg: 0.4686  loss_mask: 0.6924  loss_rpn_cls: 1.684  loss_rpn_loc: 0.2286  time: 25.2775  data_time: 0.0135  lr: 9.7405e-06  \n",
      "\u001b[32m[10/27 23:47:26 d2.utils.events]: \u001b[0m eta: 3:14:44  iter: 39  total_loss: 3.018  loss_cls: 0.913  loss_box_reg: 0.542  loss_mask: 0.6917  loss_rpn_cls: 0.6777  loss_rpn_loc: 0.2112  time: 25.4841  data_time: 0.0057  lr: 1.9731e-05  \n",
      "\u001b[32m[10/27 23:56:04 d2.utils.events]: \u001b[0m eta: 3:08:07  iter: 59  total_loss: 2.52  loss_cls: 0.7783  loss_box_reg: 0.55  loss_mask: 0.6903  loss_rpn_cls: 0.2858  loss_rpn_loc: 0.2093  time: 25.6240  data_time: 0.0095  lr: 2.972e-05  \n",
      "\u001b[32m[10/28 00:04:55 d2.utils.events]: \u001b[0m eta: 3:01:23  iter: 79  total_loss: 2.297  loss_cls: 0.6555  loss_box_reg: 0.598  loss_mask: 0.688  loss_rpn_cls: 0.1446  loss_rpn_loc: 0.1781  time: 25.8626  data_time: 0.0094  lr: 3.9711e-05  \n",
      "\u001b[32m[10/28 00:13:44 d2.utils.events]: \u001b[0m eta: 2:53:39  iter: 99  total_loss: 2.212  loss_cls: 0.5941  loss_box_reg: 0.6484  loss_mask: 0.6854  loss_rpn_cls: 0.1328  loss_rpn_loc: 0.1414  time: 25.9833  data_time: 0.0095  lr: 4.9701e-05  \n",
      "\u001b[32m[10/28 00:22:35 d2.utils.events]: \u001b[0m eta: 2:44:58  iter: 119  total_loss: 2.285  loss_cls: 0.6128  loss_box_reg: 0.6748  loss_mask: 0.682  loss_rpn_cls: 0.1145  loss_rpn_loc: 0.155  time: 26.0807  data_time: 0.0165  lr: 5.9691e-05  \n"
     ]
    }
   ],
   "source": [
    "cfg = set_up_model(max_iter=500, save=cfg_path)\n",
    "train_model(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca0ba7",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61972a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = r\"cfg_model.pickle\"\n",
    "predictor = make_inferences(cfg_path, path, microcontroller_metadata, thresh=0.1, bounding_box=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf32435",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(cfg_path, predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a8d398",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc43ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = r\"cfg_model.pickle\"\n",
    "image_path = r\"Images/train/render9701.png\"\n",
    "\n",
    "prediction(cfg_path, image_path, microcontroller_metadata, filename=\"render9701.png\", bounding_box=True, thresh=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033798e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = r\"cfg_model.pickle\"\n",
    "image_path = r\"Images/train/render1467.png\"\n",
    "\n",
    "prediction(cfg_path, image_path, microcontroller_metadata, filename=\"render1467.png\", bounding_box=True, thresh=0.25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
